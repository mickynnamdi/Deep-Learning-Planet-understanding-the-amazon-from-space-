{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ndf_test = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom tensorflow import keras\nfrom keras.layers import Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import optimizers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flatten the 'tags' column of the training data-set into a list\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list (set(flatten([l.split (' ') for l in df_train['tags'].values])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\nlabel_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the training images\n\nx_train, y_train = [], []\n\nfor img_name, label in tqdm(df_train.values, miniters=1000):\n    arr = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img_name))\n    targets = np.zeros(17)\n    for tag in label.split(' '):\n        targets[label_map[tag]] = 1 \n    x_train.append(cv2.resize(arr, (64, 64)))\n    y_train.append(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the testing images\nx_test = []\nfor img_name, label in tqdm(df_test.values[0:40669], miniters=1000):\n    img = cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n    \nfor img_name, label in tqdm(df_test.values[40669:], miniters=1000):\n    img = cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float16)/255.\nx_test  = np.array(x_test, np.float16)/255.\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for fbeta evaluation metric\n\nfrom keras import backend as K\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n\n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras import regularizers\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(64, 64,3)))\nmodel.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(17, activation='sigmoid'))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining a vgg16\nfrom tensorflow.keras.applications.resnet import ResNet152\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n\n# add a global spatial average pooling layer\nx = base_model.output\nx=Flatten()(x)\n# let's add a fully-connected layer\nx = Dense(512, activation='relu')(x)\npredictions = Dense(17, activation='sigmoid')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\n\nlearn_rate=0.0001\nopt  = optimizers.Adam(lr=learn_rate)\n    \n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics = [fbeta])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting an early callback\nepochs = 20\n \nhistory = History()\ncallbacks = [history, \n             EarlyStopping(monitor='val_loss', patience=3, verbose=1),\n             ModelCheckpoint(filepath='weights/weights.best.hdf5', verbose=1, save_best_only=True, \n                             save_weights_only=True, mode='auto')]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performing image augmentation\ndatagen = ImageDataGenerator ( horizontal_flip =True ,\nvertical_flip =True ,\nzoom_range =0.2,\nrotation_range =90 ,\nfill_mode ='reflect')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model on the batches generated by datagen.flow().\nmodel .fit_generator(datagen.flow(x_train,\ny_train,batch_size =24),steps_per_epoch =len(x_train)/32 ,\nvalidation_data = datagen.flow ( x_val,y_val,batch_size =24),\nvalidation_steps =len(x_val)/32 ,epochs =epochs ,callbacks = callbacks ,verbose =1)\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yfull_test = []\np_test = model.predict(x_test, batch_size =128, verbose=2)\nyfull_test.append(p_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.array(yfull_test [0])\nfor i in range(1, len(yfull_test)):\n    result += np.array(yfull_test[i])\nresult = pd.DataFrame(result, columns = labels)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x > 0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['tags'] = preds\ndf_test.to_csv('Final_output(vgg).csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Achieved a F-Beta score of 0.90833 using VGG16"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}